# -*- coding: utf-8 -*-
"""Object_detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10mmfjoLkEnjIWYSL4refLhdP6KZFRevF
"""

# ===========================================
# ðŸ“Œ Hybrid Object + Digit Detection Project
# ===========================================

# 1. Install dependencies
!pip install -q tensorflow==2.19.0 tensorflow-hub opencv-python-headless matplotlib

import tensorflow as tf
import tensorflow_hub as hub
import numpy as np
import cv2
import matplotlib.pyplot as plt
from google.colab import files

print("âœ… TensorFlow version:", tf.__version__)

IMAGE_PATH = "test.jpeg"                 # local file to read
COCO_SCORE_THRESH = 0.5                 # COCO detection threshold
DIGIT_SCORE_THRESH = 0.85               # minimum softmax score to accept a digit
DIGIT_NMS_IOU = 0.3                     # NMS IoU for digit boxes
MIN_DIGIT_AREA = 50                     # ignore tiny contours
MAX_DIGIT_AREA = 20000                  # ignore huge regions (optional)
MNIST_TRAIN_EPOCHS = 2                  # set 0 to skip training/assume pretrained
VERBOSE = True

# ----------------------------
# Load models
# ----------------------------
import os
if VERBOSE: print("Loading TF-Hub COCO detector (SSD MobileNet V2)...")
coco_model = hub.load("https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2")
if VERBOSE: print("COCO model loaded.")

# Build a small MNIST classifier (conv net)
def build_digit_model():
    inp = tf.keras.layers.Input((28,28,1))
    x = tf.keras.layers.Conv2D(32,3,activation='relu')(inp)
    x = tf.keras.layers.MaxPool2D()(x)
    x = tf.keras.layers.Conv2D(64,3,activation='relu')(x)
    x = tf.keras.layers.MaxPool2D()(x)
    x = tf.keras.layers.Flatten()(x)
    x = tf.keras.layers.Dense(128, activation='relu')(x)
    out = tf.keras.layers.Dense(10, activation='softmax')(x)
    m = tf.keras.Model(inp, out)
    m.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    return m

digit_model = build_digit_model()

# Train quickly (or skip by setting MNIST_TRAIN_EPOCHS = 0)
if MNIST_TRAIN_EPOCHS > 0:
    if VERBOSE: print("Training MNIST classifier for", MNIST_TRAIN_EPOCHS, "epoch(s)...")
    (xtr, ytr), (xte, yte) = tf.keras.datasets.mnist.load_data()
    xtr = (xtr.astype(np.float32) / 255.0)[..., None]
    xte = (xte.astype(np.float32) / 255.0)[..., None]
    digit_model.fit(xtr, ytr, validation_data=(xte,yte), epochs=MNIST_TRAIN_EPOCHS, batch_size=128, verbose=1)
    if VERBOSE: print("MNIST training done.")
else:
    if VERBOSE: print("Skipping MNIST training (MNIST_TRAIN_EPOCHS=0).")

# ----------------------------
# COCO label map (partial, extend if needed)
# ----------------------------
coco_labels = {
    1: "person", 2: "bicycle", 3: "car", 4: "motorcycle", 5: "airplane",
    6: "bus", 7: "train", 8: "truck", 9: "boat", 10: "traffic light",
    11: "fire hydrant", 13: "stop sign", 14: "parking meter", 15: "bench",
    16: "bird", 17: "cat", 18: "dog", 19: "horse", 20: "sheep", 21: "cow",
    22: "elephant", 23: "bear", 24: "zebra", 25: "giraffe"
}

# ----------------------------
# Utilities
# ----------------------------
def safe_float(x):
    # convert tensorflow/numpy/tensor-like value to python float
    try:
        if hasattr(x, "numpy"):
            x = x.numpy()
    except:
        pass
    a = np.array(x)
    if a.size == 0:
        return 0.0
    return float(a.ravel()[0])

def resize_pad_to_28(img):
    # img: single-channel patch (grayscale), arbitrary size
    # Resize while keeping aspect ratio, pad to 28x28
    h, w = img.shape[:2]
    # compute scale to fit inside 20x20 box (MNIST style has digit centered but 28x28)
    # but we'll scale so max dimension becomes 20 then pad
    max_dim = max(h,w)
    if max_dim == 0:
        return np.zeros((28,28), dtype=np.float32)
    scale = 20.0 / max_dim
    new_w = max(1, int(round(w * scale)))
    new_h = max(1, int(round(h * scale)))
    resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)
    # create 28x28 canvas and center the resized image
    canvas = np.zeros((28,28), dtype=np.uint8)
    x_offset = (28 - new_w) // 2
    y_offset = (28 - new_h) // 2
    canvas[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = resized
    # optional: normalization to [0,1]
    return canvas.astype(np.float32) / 255.0

# ----------------------------
# COCO detection wrapper (expects uint8)
# ----------------------------
def run_coco_detection_rgb(image_rgb):
    # image_rgb: HxWx3 uint8 (RGB)
    tensor = tf.convert_to_tensor(image_rgb[np.newaxis, ...], dtype=tf.uint8)
    out = coco_model(tensor)
    # convert tensors -> numpy arrays
    return {k: v.numpy() for k, v in out.items()}

# ----------------------------
# Digit candidate proposals using contour detection (fast)
# ----------------------------
def propose_digit_regions(image_rgb):
    """
    Returns list of candidate boxes in absolute pixel coords: (x, y, w, h)
    Approach: adaptive threshold + morphology + contour filtering
    """
    gray = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY)
    # adaptive threshold to handle variable illumination
    th = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                               cv2.THRESH_BINARY_INV, 15, 7)
    # morphological opening to remove noise
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))
    opening = cv2.morphologyEx(th, cv2.MORPH_OPEN, kernel, iterations=1)
    # find contours
    contours, _ = cv2.findContours(opening, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    candidates = []
    H, W = gray.shape
    for cnt in contours:
        x,y,w,h = cv2.boundingRect(cnt)
        area = w*h
        # size filters (tweakable)
        if area < MIN_DIGIT_AREA or area > MAX_DIGIT_AREA:
            continue
        # aspect ratio filter (digits usually not extremely wide/tall)
        ar = w / float(h + 1e-6)
        if ar < 0.2 or ar > 5.0:
            continue
        # keep margin and clamp to image
        pad = 2
        x1 = max(0, x-pad)
        y1 = max(0, y-pad)
        x2 = min(W, x+w+pad)
        y2 = min(H, y+h+pad)
        candidates.append((x1, y1, x2-x1, y2-y1))
    return candidates

# ----------------------------
# Classify candidates with MNIST model and NMS
# ----------------------------
def classify_digit_candidates(image_rgb, candidates):
    boxes = []
    scores = []
    labels = []
    for (x,y,w,h) in candidates:
        patch = image_rgb[y:y+h, x:x+w]
        # convert to grayscale if needed
        gray = cv2.cvtColor(patch, cv2.COLOR_RGB2GRAY) if patch.ndim==3 else patch
        # preprocess: resize & pad to 28x28
        inp28 = resize_pad_to_28(gray)  # float32 [0,1]
        inp28 = inp28.reshape(1,28,28,1).astype(np.float32)
        pred = digit_model.predict(inp28, verbose=0)  # softmax
        score = float(np.max(pred))
        label = int(np.argmax(pred))
        if score >= DIGIT_SCORE_THRESH:
            # record box as [y1,x1,y2,x2] for NMS (absolute coords)
            boxes.append([y, x, y+h, x+w])
            scores.append(score)
            labels.append(label)
    if len(boxes) == 0:
        return []
    boxes_np = np.array(boxes, dtype=np.float32)
    scores_np = np.array(scores, dtype=np.float32)
    labels_np = np.array(labels, dtype=np.int32)

    final = []
    # perform per-class NMS
    for digit in np.unique(labels_np):
        idxs = np.where(labels_np == digit)[0]
        if idxs.size == 0:
            continue
        boxes_digit = boxes_np[idxs]
        scores_digit = scores_np[idxs]
        selected = tf.image.non_max_suppression(boxes_digit, scores_digit,
                                                max_output_size=50,
                                                iou_threshold=DIGIT_NMS_IOU,
                                                score_threshold=DIGIT_SCORE_THRESH)
        selected = selected.numpy().tolist()
        for s in selected:
            i = idxs[s]
            y1,x1,y2,x2 = boxes_np[i].astype(int).tolist()
            w_box = x2 - x1
            h_box = y2 - y1
            final.append((x1, y1, w_box, h_box, int(labels_np[i]), float(scores_np[i])))
    return final

# ----------------------------
# Visualization: draw boxes & labels without cutting text
# ----------------------------
def draw_and_show(image_rgb, coco_results, digit_detections, coco_thresh=COCO_SCORE_THRESH):
    img_out = image_rgb.copy()
    H, W = img_out.shape[:2]
    summary = []

    # COCO detections: model returns arrays shaped (1,N,4) etc.
    boxes = coco_results.get("detection_boxes", None)
    classes = coco_results.get("detection_classes", None)
    scores = coco_results.get("detection_scores", None)
    if boxes is not None and classes is not None and scores is not None:
        # flatten first batch dim if present
        if boxes.ndim == 3 and boxes.shape[0] == 1:
            boxes = boxes[0]
        if classes.ndim == 2 and classes.shape[0] == 1:
            classes = classes[0]
        if scores.ndim == 2 and scores.shape[0] == 1:
            scores = scores[0]
        N = len(scores)
        for i in range(N):
            score = safe_float(scores[i])
            if score < coco_thresh:
                continue
            # box format [ymin, xmin, ymax, xmax] normalized
            box = np.array(boxes[i]).ravel()[:4]
            ymin, xmin, ymax, xmax = map(safe_float, box)
            left = int(xmin * W); right = int(xmax * W)
            top = int(ymin * H); bottom = int(ymax * H)
            class_id = int(safe_float(classes[i]))
            label = coco_labels.get(class_id, f"class_{class_id}")
            # draw box
            cv2.rectangle(img_out, (left, top), (right, bottom), (0,255,0), 2)
            # text position: above box if space, else inside box near top
            text = f"{label} {score:.2f}"
            text_y = max(top-8, 12)
            cv2.putText(img_out, text, (left, text_y),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)
            summary.append(f"{label} ({score:.2f}) at [{left},{top},{right},{bottom}]")

    # Digit detections (list of (x,y,w,h,label,score))
    for (x,y,w,h,label,score) in digit_detections:
        left, top, right, bottom = x, y, x+w, y+h
        cv2.rectangle(img_out, (left, top), (right, bottom), (255,0,0), 2)
        text = f"digit_{label} {score:.2f}"
        text_y = max(top-8, 12)
        cv2.putText(img_out, text, (left, text_y),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,0), 2)
        summary.append(f"digit_{label} ({score:.2f}) at [{left},{top},{right},{bottom}]")

    # Show image (matplotlib expects RGB; we already have RGB)
    plt.figure(figsize=(12,8))
    plt.imshow(img_out)
    plt.axis("off")
    plt.show()

    # Print summary
    print("\nSummary of detections:")
    if len(summary) == 0:
        print(" - Nothing detected above thresholds.")
    else:
        for s in summary:
            print(" -", s)

# ----------------------------
# MAIN: Read local image, run both detectors, visualize
# ----------------------------
if not os.path.exists(IMAGE_PATH):
    raise FileNotFoundError(f"Local image file not found: {IMAGE_PATH}. Put your image named '{IMAGE_PATH}' in working dir.")

# Read as BGR then convert to RGB (OpenCV default)
img_bgr = cv2.imread(IMAGE_PATH)
if img_bgr is None:
    raise RuntimeError(f"Failed to read image: {IMAGE_PATH}")
img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)

if VERBOSE: print("Running COCO detection...")
coco_out = run_coco_detection_rgb(img_rgb)

if VERBOSE: print("Proposing digit regions via contours...")
candidates = propose_digit_regions(img_rgb)
if VERBOSE: print(f" - candidate regions found: {len(candidates)}")

if VERBOSE: print("Classifying digit candidates...")
digit_dets = classify_digit_candidates(img_rgb, candidates)
if VERBOSE: print(f" - digit detections (after NMS): {len(digit_dets)}")

# Draw and show
draw_and_show(img_rgb, coco_out, digit_dets)

# Load Models
# ----------------------
coco_model = hub.load("https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2")

mnist_model = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])
# Train briefly on MNIST to make it useful
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0
mnist_model.compile(optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"])
mnist_model.fit(x_train, y_train, epochs=1, batch_size=128, verbose=1)

# COCO labels
coco_labels = {1:"person", 2:"bicycle", 3:"car", 18:"dog", 17:"cat", 44:"bottle",
               47:"cup", 48:"fork", 49:"knife", 50:"spoon", 52:"banana", 53:"apple"}

# ----------------------
# Detection Functions
# ----------------------
def run_coco_detection(image_np):
    img_uint8 = tf.convert_to_tensor(image_np, dtype=tf.uint8)  # must be uint8
    img_exp = tf.expand_dims(img_uint8, axis=0)
    results = coco_model(img_exp)
    return {k: v.numpy() for k, v in results.items()}

def run_digit_detection(image_np):
    gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)
    _, thresh = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY_INV)
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    detections = []
    for cnt in contours:
        x, y, w, h = cv2.boundingRect(cnt)
        if w < 10 or h < 10:  # ignore tiny noise
            continue
        roi = gray[y:y+h, x:x+w]
        roi_resized = cv2.resize(roi, (28, 28)) / 255.0
        roi_resized = np.expand_dims(roi_resized, axis=(0, -1))
        pred = mnist_model.predict(roi_resized, verbose=0)
        label = np.argmax(pred)
        score = np.max(pred)
        detections.append((x, y, w, h, label, score))
    return detections

# ----------------------
# Visualization
# ----------------------
def plot_detections(image_np, coco_results, digit_results):
    img_out = image_np.copy()

    # COCO objects
    for i in range(len(coco_results["detection_scores"][0])):
        score = coco_results["detection_scores"][0][i]
        if score < 0.5:
            continue
        ymin, xmin, ymax, xmax = coco_results["detection_boxes"][0][i]
        h, w, _ = img_out.shape
        (xmin, xmax, ymin, ymax) = (int(xmin*w), int(xmax*w), int(ymin*h), int(ymax*h))
        class_id = int(coco_results["detection_classes"][0][i])
        label = coco_labels.get(class_id, str(class_id))
        cv2.rectangle(img_out, (xmin, ymin), (xmax, ymax), (0,255,0), 2)
        cv2.putText(img_out, f"{label} {score:.2f}", (xmin, ymin-10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 2)

    # MNIST digits
    for (x,y,w,h,label,score) in digit_results:
        cv2.rectangle(img_out, (x,y), (x+w,y+h), (255,0,0), 2)
        cv2.putText(img_out, f"Digit {label} {score:.2f}", (x, y-10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,0,0), 2)

    plt.figure(figsize=(10,10))
    plt.imshow(img_out)
    plt.axis("off")
    plt.show()

# ----------------------
# Upload + Run
# ----------------------
uploaded = files.upload()
img_path = list(uploaded.keys())[0]
img = cv2.imread(img_path)
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

coco_results = run_coco_detection(img)
digit_results = run_digit_detection(img)

plot_detections(img, coco_results, digit_results)

